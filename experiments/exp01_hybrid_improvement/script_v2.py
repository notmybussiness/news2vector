"""
EXP-01 ê°œì„  ì‹¤í—˜ v2: ì¿¼ë¦¬ í™•ì¥ + í•„í„° ìš°ì„  ê²€ìƒ‰

ê°€ì„¤: ì¢…ëª©ëª…ì— ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ë©´ ë²¡í„° ê²€ìƒ‰ ì •í™•ë„ê°€ í–¥ìƒëœë‹¤
ë°©ë²•:
  1. ì¿¼ë¦¬ í™•ì¥: "ì‚¼ì„±ì „ì" â†’ "ì‚¼ì„±ì „ì ì£¼ê°€ ë°˜ë„ì²´ ì‹¤ì "
  2. í•„í„° ìš°ì„ : ì œëª©ì— ì¢…ëª©ëª… ìˆëŠ” ê²ƒ ë¨¼ì €, ë‚˜ë¨¸ì§€ëŠ” ì˜ë¯¸ ê²€ìƒ‰
"""

import json
import sys
import os
from datetime import datetime
from pathlib import Path

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "data-pipeline"))
from dotenv import load_dotenv

load_dotenv(os.path.join(os.path.dirname(__file__), "..", "..", ".env"))

from src.embeddings import KoSRoBERTaEmbedding
from src.storage import MilvusClient


# ì¢…ëª©-ê´€ë ¨ í‚¤ì›Œë“œ ì‚¬ì „
STOCK_KEYWORDS = {
    "ì‚¼ì„±ì „ì": ["ì‚¼ì„±ì „ì", "ë°˜ë„ì²´", "ê°¤ëŸ­ì‹œ", "ë©”ëª¨ë¦¬"],
    "SKí•˜ì´ë‹‰ìŠ¤": ["SKí•˜ì´ë‹‰ìŠ¤", "HBM", "ë°˜ë„ì²´", "ë©”ëª¨ë¦¬"],
    "ë„¤ì´ë²„": ["ë„¤ì´ë²„", "ê²€ìƒ‰", "ë¼ì¸", "ì›¹íˆ°"],
    "ì¹´ì¹´ì˜¤": ["ì¹´ì¹´ì˜¤", "ì¹´í†¡", "ì¹´ì¹´ì˜¤í˜ì´", "ì¹´ì¹´ì˜¤ë±…í¬"],
    "LGì—ë„ˆì§€ì†”ë£¨ì…˜": ["LGì—ë„ˆì§€ì†”ë£¨ì…˜", "ë°°í„°ë¦¬", "2ì°¨ì „ì§€", "ì „ê¸°ì°¨"],
}


def expanded_search(embedder, storage, query, top_k=5):
    """ì¿¼ë¦¬ í™•ì¥ ê²€ìƒ‰: ì¢…ëª©ëª… + ê´€ë ¨ í‚¤ì›Œë“œ"""
    keywords = STOCK_KEYWORDS.get(query, [query])
    expanded_query = " ".join(keywords[:3])  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œ

    embedding = embedder.embed(expanded_query)[0].tolist()
    results = storage.search(embedding, top_k=top_k)

    return results, expanded_query


def filter_first_search(embedder, storage, query, top_k=5):
    """í•„í„° ìš°ì„  ê²€ìƒ‰: ì œëª©ì— ì¢…ëª©ëª… ìˆëŠ” ê²ƒ ë¨¼ì €"""
    embedding = embedder.embed(query)[0].tolist()

    # ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§
    candidates = storage.search(embedding, top_k=50)

    # 1ë‹¨ê³„: ì œëª©ì— ì¢…ëª©ëª… ìˆëŠ” ê²ƒ
    exact_matches = [
        r for r in candidates if query.lower() in r.get("title", "").lower()
    ]

    # 2ë‹¨ê³„: ë‚˜ë¨¸ì§€ ì˜ë¯¸ ê²€ìƒ‰ ê²°ê³¼
    remaining = [r for r in candidates if r not in exact_matches]

    # í•©ì¹˜ê¸°
    final = exact_matches[:top_k]
    if len(final) < top_k:
        final.extend(remaining[: top_k - len(final)])

    return final


def run_comparison():
    print("\n" + "=" * 60)
    print("EXP-01 ê°œì„  v2: ì¿¼ë¦¬ í™•ì¥ + í•„í„° ìš°ì„ ")
    print("=" * 60)

    embedder = KoSRoBERTaEmbedding()
    storage = MilvusClient()
    storage.connect()

    queries = list(STOCK_KEYWORDS.keys())

    results = {
        "experiment": "exp01_improved_v2",
        "timestamp": datetime.now().isoformat(),
        "methods": {},
    }

    for query in queries:
        embedding = embedder.embed(query)[0].tolist()

        # ë°©ë²• A: ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰
        vector_results = storage.search(embedding, top_k=5)
        vector_relevant = sum(
            1 for r in vector_results if query.lower() in r.get("title", "").lower()
        )

        # ë°©ë²• B: ì¿¼ë¦¬ í™•ì¥
        expanded_results, expanded_query = expanded_search(embedder, storage, query)
        expanded_relevant = sum(
            1 for r in expanded_results if query.lower() in r.get("title", "").lower()
        )

        # ë°©ë²• C: í•„í„° ìš°ì„ 
        filter_results = filter_first_search(embedder, storage, query)
        filter_relevant = sum(
            1 for r in filter_results if query.lower() in r.get("title", "").lower()
        )

        results["methods"][query] = {
            "vector_only": {
                "relevant": vector_relevant,
                "precision": vector_relevant / 5,
            },
            "query_expansion": {
                "relevant": expanded_relevant,
                "precision": expanded_relevant / 5,
                "query": expanded_query,
            },
            "filter_first": {
                "relevant": filter_relevant,
                "precision": filter_relevant / 5,
            },
        }

        print(f"\n{query}:")
        print(f"  ë²¡í„° ê²€ìƒ‰: {vector_relevant}/5 ({vector_relevant*20}%)")
        print(
            f"  ì¿¼ë¦¬ í™•ì¥: {expanded_relevant}/5 ({expanded_relevant*20}%) - '{expanded_query}'"
        )
        print(
            f"  í•„í„° ìš°ì„ : {filter_relevant}/5 ({filter_relevant*20}%) {'âœ… ìµœê³ ' if filter_relevant >= max(vector_relevant, expanded_relevant) and filter_relevant > 0 else ''}"
        )

    # í‰ê·  ê³„ì‚°
    avg_vector = sum(
        r["vector_only"]["precision"] for r in results["methods"].values()
    ) / len(queries)
    avg_expanded = sum(
        r["query_expansion"]["precision"] for r in results["methods"].values()
    ) / len(queries)
    avg_filter = sum(
        r["filter_first"]["precision"] for r in results["methods"].values()
    ) / len(queries)

    results["summary"] = {
        "avg_vector": avg_vector,
        "avg_query_expansion": avg_expanded,
        "avg_filter_first": avg_filter,
        "best_method": (
            "filter_first"
            if avg_filter >= max(avg_vector, avg_expanded)
            else ("query_expansion" if avg_expanded > avg_vector else "vector_only")
        ),
    }

    print("\n" + "=" * 60)
    print("ğŸ“Š ì¢…í•© ê²°ê³¼")
    print("=" * 60)
    print(f"  ë²¡í„° ê²€ìƒ‰: {avg_vector*100:.1f}%")
    print(f"  ì¿¼ë¦¬ í™•ì¥: {avg_expanded*100:.1f}%")
    print(
        f"  í•„í„° ìš°ì„ : {avg_filter*100:.1f}% {'â† ìµœê³ !' if avg_filter >= max(avg_vector, avg_expanded) else ''}"
    )
    print(f"\n  ê°œì„ ë„ (í•„í„° ìš°ì„  vs ë²¡í„°): {(avg_filter - avg_vector)*100:+.1f}%p")

    # ì €ì¥
    output_dir = Path(__file__).parent
    with open(output_dir / "results_v2.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ ê²°ê³¼ ì €ì¥: {output_dir}/results_v2.json")

    storage.disconnect()
    return results


if __name__ == "__main__":
    run_comparison()
